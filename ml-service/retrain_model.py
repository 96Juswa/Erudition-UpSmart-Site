# retrain_model.py
# Simple model retraining script - no Google Notebook needed!

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import joblib
import os

print("ðŸš€ Starting Simple Model Retraining\n")
print(f"ðŸ“Š Scikit-learn version: {joblib.__version__}")

# Define features (these match your app.py)
feature_columns = [
    'PortfolioCount', 'AverageRatings', 'TransactionCount',
    'CompletedTransactions', 'ReviewCount', 'StarCount',
    'PositiveReviews', 'NeutralReviews', 'NegativeReviews',
    'CompletionRate', 'CancellationRate', 'BioLength',
    'BioWordCount', 'PositiveReviewRatio', 'ReviewCoverage',
    'EngagementIndex'
]

print(f"âœ… Using {len(feature_columns)} features")

# Create synthetic training data
# This creates realistic data based on the feature relationships
np.random.seed(42)
n_samples = 2000

print(f"ðŸ“Š Generating {n_samples} training samples...")

data = {}

# Generate base features
data['PortfolioCount'] = np.random.randint(0, 25, n_samples)
data['AverageRatings'] = np.random.uniform(1.5, 5.0, n_samples)
data['TransactionCount'] = np.random.randint(1, 150, n_samples)
data['CompletedTransactions'] = [
    int(t * np.random.uniform(0.6, 1.0)) 
    for t in data['TransactionCount']
]
data['ReviewCount'] = [
    int(min(t * np.random.uniform(0.2, 0.8), c)) 
    for t, c in zip(data['TransactionCount'], data['CompletedTransactions'])
]
data['StarCount'] = [
    int(r * np.random.uniform(3, 5)) 
    for r in data['ReviewCount']
]

# Sentiment reviews
data['PositiveReviews'] = [
    int(r * np.random.uniform(0.5, 0.9)) 
    for r in data['ReviewCount']
]
data['NeutralReviews'] = [
    int(r * np.random.uniform(0.0, 0.3)) 
    for r in data['ReviewCount']
]
data['NegativeReviews'] = [
    max(0, r - p - n) 
    for r, p, n in zip(data['ReviewCount'], data['PositiveReviews'], data['NeutralReviews'])
]

# Calculated features
data['CompletionRate'] = [
    (c / t * 100) if t > 0 else 0 
    for c, t in zip(data['CompletedTransactions'], data['TransactionCount'])
]
data['CancellationRate'] = [
    ((t - c) / t * 100) if t > 0 else 0 
    for c, t in zip(data['CompletedTransactions'], data['TransactionCount'])
]

data['BioLength'] = np.random.randint(0, 500, n_samples)
data['BioWordCount'] = [int(bl / np.random.uniform(4, 8)) for bl in data['BioLength']]

data['PositiveReviewRatio'] = [
    (p / r) if r > 0 else 0.5 
    for p, r in zip(data['PositiveReviews'], data['ReviewCount'])
]
data['ReviewCoverage'] = [
    (r / t) if t > 0 else 0 
    for r, t in zip(data['ReviewCount'], data['TransactionCount'])
]

data['EngagementIndex'] = [
    tc + rc + pc + bl + bw 
    for tc, rc, pc, bl, bw in zip(
        data['TransactionCount'], 
        data['ReviewCount'], 
        data['PortfolioCount'],
        data['BioLength'],
        data['BioWordCount']
    )
]

df = pd.DataFrame(data)

# Create realistic trust scores based on the features
# This mimics what a real trust score would look like
trust_scores = (
    df['AverageRatings'] * 12 +  # 0-60 points
    df['CompletionRate'] * 0.25 +  # 0-25 points
    df['PositiveReviewRatio'] * 15 +  # 0-15 points
    np.clip(df['TransactionCount'] / 10, 0, 10) +  # 0-10 points (capped)
    np.clip(df['PortfolioCount'], 0, 5) +  # 0-5 points (capped)
    np.random.normal(0, 3, n_samples)  # Some noise
)

# Clamp to 0-100 range
df['TrustRating'] = np.clip(trust_scores, 0, 100)

print(f"âœ… Data generated")
print(f"   Trust Score range: {df['TrustRating'].min():.1f} - {df['TrustRating'].max():.1f}")
print(f"   Trust Score mean: {df['TrustRating'].mean():.1f}")

# Prepare features and target
X = df[feature_columns]
y = df['TrustRating']

print(f"\nðŸ”§ Building pipeline...")

# Create preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('scaler', StandardScaler(), feature_columns)
    ],
    remainder='drop'
)

# Create full pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    ))
])

print(f"ðŸŽ¯ Training model...")
pipeline.fit(X, y)

# Evaluate on training data
train_score = pipeline.score(X, y)
print(f"âœ… Training RÂ² score: {train_score:.4f}")

# Test prediction
test_sample = pd.DataFrame([{
    'PortfolioCount': 5,
    'AverageRatings': 4.0,
    'TransactionCount': 10,
    'CompletedTransactions': 9,
    'ReviewCount': 5,
    'StarCount': 20,
    'PositiveReviews': 4,
    'NeutralReviews': 1,
    'NegativeReviews': 0,
    'CompletionRate': 90.0,
    'CancellationRate': 10.0,
    'BioLength': 100,
    'BioWordCount': 20,
    'PositiveReviewRatio': 0.8,
    'ReviewCoverage': 0.5,
    'EngagementIndex': 150
}])

prediction = pipeline.predict(test_sample)[0]
print(f"ðŸ§ª Test prediction: {prediction:.2f}")

# Save the model
model_dir = 'models'
os.makedirs(model_dir, exist_ok=True)
model_path = os.path.join(model_dir, 'trust_pipeline_best.joblib')

print(f"\nðŸ’¾ Saving model to {model_path}...")
joblib.dump(pipeline, model_path)

file_size = os.path.getsize(model_path) / 1024
print(f"âœ… Model saved! Size: {file_size:.2f} KB")

# Test loading the model
print(f"\nðŸ§ª Testing model loading...")
loaded_model = joblib.load(model_path)
test_pred = loaded_model.predict(test_sample)[0]
print(f"âœ… Model loads correctly! Test prediction: {test_pred:.2f}")

print("\n" + "="*60)
print("âœ… SUCCESS! Model retrained and saved.")
print("="*60)
print("ðŸ“¦ Next steps:")
print("   1. The new model is at: ./models/trust_pipeline_best.joblib")
print("   2. Run: git add models/trust_pipeline_best.joblib")
print("   3. Run: git commit -m 'Update ML model for compatibility'")
print("   4. Run: git push origin main")
print("   5. Redeploy on Render.com")
print("="*60)